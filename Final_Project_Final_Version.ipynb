{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WIIwbKjwJKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2ed0c7-1498-4ad8-aec7-67c372b9279f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 12.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 240 kB 9.6 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q emoji --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO9m8wvRvyzL"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textwrap import wrap\n",
        "import re\n",
        "from emoji import demojize\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kTax81l7brz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "# plot setting\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "# setup random seed for split \n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFAdUZVm7ir7"
      },
      "outputs": [],
      "source": [
        "# Install bert tokenizer\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'   # model 1: 'bert-base-cased'; model 2: 'bert-large-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "# Pre trained model store path\n",
        "PRE_TRAINED_DICT_NAME = 'checkpoints/' + PRE_TRAINED_MODEL_NAME + '/pretrain_model_dict.bin'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/CS675 Machine Learning/Final_Project/' # Jintan\n",
        "#path = '/content/drive/MyDrive/MLProject/' #Haochen's google drive"
      ],
      "metadata": {
        "id": "fnr3N8Y4AEgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c0be87-158c-4fb2-cefd-545c255b723d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Pretrain Data Setup**\n",
        "\n",
        "**-----------------------------------------**"
      ],
      "metadata": {
        "id": "Ve4LCyvV9zlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label the IMDB sentiment\n",
        "df = pd.read_csv(\"imdb_reviews.csv\") # due to the size of the dataset, we are not providing them in this notebook\n",
        "\n",
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)\n",
        "\n",
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "metadata": {
        "id": "6R1bTUaG90xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAH1BgwkOmaY"
      },
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Dataset and Model Setup**\n",
        "\n",
        "**-----------------------------------------**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset class \n",
        "class SentimentDataset(Dataset):\n",
        "\n",
        "  def __init__(self, text_input, label, tokenizer, max_token_len):\n",
        "    # input and label\n",
        "    self.text_input = text_input\n",
        "    self.label = label\n",
        "\n",
        "    # text tokenizer\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "    # tokenzier property\n",
        "    self.max_token_len = max_token_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.text_input)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    # get text and label\n",
        "    text_input = str(self.text_input[item])\n",
        "    label = self.label[item]\n",
        "\n",
        "    # tokenize string\n",
        "    tokenized_input = self.tokenizer.encode_plus(text_input, add_special_tokens=True, \n",
        "                                                 max_length=self.max_token_len, pad_to_max_length=True,\n",
        "                                                 return_attention_mask=True)\n",
        "\n",
        "    return tokenized_input['input_ids'], tokenized_input['attention_mask'], label"
      ],
      "metadata": {
        "id": "Ce4qaqqxUPwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to create dataset and dataloader\n",
        "def generate_dataloader(data, tokenizer, max_token_len, batch_size, num_workers):\n",
        "  dataset = SentimentDataset(text_input=data.content.to_numpy(), label=data.sentiment.to_numpy(),\n",
        "                             tokenizer=tokenizer, max_token_len=max_token_len)\n",
        "\n",
        "  return DataLoader(ds, batch_size=batch_size, num_workers=num_workers)"
      ],
      "metadata": {
        "id": "xg31-deeyt4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mOI263C8BIJ"
      },
      "outputs": [],
      "source": [
        "# Padding size 160 and class number 3\n",
        "# NOTE: we get size 160 by analyzing the histogram of the sequence size\n",
        "MAX_SEQ_LEN = 160\n",
        "NUM_SENTIMENT = 3\n",
        "\n",
        "# split data to train, eval, test\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKER = 2\n",
        "\n",
        "data_train, data_test = train_test_split(data, test_size=0.3, random_state=RANDOM_SEED)\n",
        "data_val, data_test = train_test_split(data_test, test_size=0.5, random_state=RANDOM_SEED)\n",
        "\n",
        "train_data_loader = generate_dataloader(data_train, tokenizer, MAX_SEQ_LEN, BATCH_SIZE, NUM_WORKER)\n",
        "val_data_loader = generate_dataloader(data_val, tokenizer, MAX_SEQ_LEN, BATCH_SIZE, NUM_WORKER)\n",
        "test_data_loader = generate_dataloader(data_test, tokenizer, MAX_SEQ_LEN, BATCH_SIZE, NUM_WORKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwPrXx8KQWfa"
      },
      "outputs": [],
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "    self.classifier = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, output = self.bert(input_ids=input_ids, attention_mask=attention_mask).to_tuple()\n",
        "    output = self.dropout(output)\n",
        "    return self.classifier(output)\n",
        "\n",
        "model = SentimentClassifier(NUM_SENTIMENT, dropout)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7FIOFP4FjsI"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "EPOCHS = 10\n",
        "\n",
        "# optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# learning rate scheduler # TODO\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSU_GFSIQ6IL"
      },
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Define training & evaluatiojn function**\n",
        "\n",
        "**-----------------------------------------**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Lyz1JbiQ5ny"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, loss_fn, optimizer, scheduler, device, n_examples):\n",
        "  # enable weight update\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for input_ids, attention_mask, label in data_loader:\n",
        "    # convert to acceleration unit\n",
        "    input_ids = text_input.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # forward\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # compute loss\n",
        "    _, pred = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    # update gradient\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    # compute accuracy of current training epoch\n",
        "    correct_predictions += torch.sum(pred == label)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, data_loader, loss_fn, device, n_examples):\n",
        "  # freeze backprop gradient compute\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for input_ids, attention_mask, label in data_loader:\n",
        "      # convert to acceleration unit\n",
        "      input_ids = text_input.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # forward\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      # compute loss\n",
        "      _, pred = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      # compute accuracy of current evaluation epoch\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "OCkyR0epbr56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(EPOCHS, model, train_data_loader, val_data_loader, data_train, data_val, loss_fn, optimizer, scheduler, device, dict_name):\n",
        "  history = defaultdict(list)\n",
        "  best_acc = 0\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "\n",
        "    print('Starting Epoch {}...'.format(epoch))\n",
        "\n",
        "    # train\n",
        "    train_acc, train_loss = train(\n",
        "      model,\n",
        "      train_data_loader,    \n",
        "      loss_fn, \n",
        "      optimizer,\n",
        "      scheduler, \n",
        "      device, \n",
        "      len(data_train)\n",
        "    )\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    # evaluate\n",
        "    val_acc, val_loss = eval(\n",
        "      model,\n",
        "      val_data_loader,\n",
        "      loss_fn, \n",
        "      device, \n",
        "      len(data_val)\n",
        "    )\n",
        "    print(f'Val loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "    # record\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    # save model ckpt based on evaluation accuracy\n",
        "    if val_acc > best_acc:\n",
        "      torch.save(model.state_dict(), path + dict_name)\n",
        "      best_accuracy = val_acc\n",
        "      print(\"new val acc best! saving model...\")\n",
        "\n",
        "  return history\n",
        "\n",
        "history = train(EPOCHS, model, train_data_loader, val_data_loader, data_train, data_val, loss_fn, optimizer, scheduler, device, PRE_TRAINED_DICT_NAME)"
      ],
      "metadata": {
        "id": "4zvvE4jApqOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Evaluate pre-trained model accuracy**\n",
        "\n",
        "**-----------------------------------------**"
      ],
      "metadata": {
        "id": "HlCr3OF7sK5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EiQQ1ERTJgR"
      },
      "outputs": [],
      "source": [
        "# uncomment this line if you reload this notebook and wish to continue from previous checkpoint\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/MLProject/checkpoints/bert-large-cased/pretrain_model_dict.bin\"))\n",
        "\n",
        "test_acc, test_loss = eval(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(data_test)\n",
        ")\n",
        "\n",
        "print(\"Test accuracy {}\".format(test_acc.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINE TUNNING STARTS HERE**"
      ],
      "metadata": {
        "id": "fflMqeCkdnm8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCbSZrE_IwBG"
      },
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Read fine-tune Data**\n",
        "\n",
        "**-----------------------------------------**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# herbal\n",
        "data_herbal = pd.read_csv(path + \"/data/Labeling_Sample_herbal_medicine.csv\")\n",
        "data_herbal.columns = ['content', 'label']\n",
        "print(\"Herbal\")\n",
        "print(len(data_herbal))\n",
        "\n",
        "# integrative medicine\n",
        "data_im = pd.read_csv(path + \"/data/integrative_medicine_labeled_csv.csv\")\n",
        "data_im.columns = ['content', 'label']\n",
        "data_im = data_im.drop(data_im.index[127:len(data_im)])\n",
        "print(\"integrative medicine\")\n",
        "print(len(data_im))\n",
        "\n",
        "# qi gong tweet & reply\n",
        "data_qg_tweet = pd.read_csv(path + \"/data/qi_gong_tweet.csv\")\n",
        "data_qg_tweet.columns = ['content', 'label']\n",
        "print(\"qi gong tweet\")\n",
        "print(len(data_qg_tweet))\n",
        "\n",
        "data_qg_reply = pd.read_csv(path + \"/data/qi_gong_reply.csv\")\n",
        "data_qg_reply.columns = ['content', 'label']\n",
        "print(\"qi gong reply\")\n",
        "print(len(data_qg_reply))\n",
        "\n",
        "# acpuate tweet & reply\n",
        "data_acup_tweet = pd.read_csv(path + \"/data/acup_tweet.csv\")\n",
        "data_acup_tweet.columns = ['content', 'label']\n",
        "print(\"acpuate tweet\")\n",
        "print(len(data_acup_tweet))\n",
        "\n",
        "data_acup_reply = pd.read_csv(path + \"/data/acup_reply.csv\")\n",
        "data_acup_reply.columns = ['content', 'label']\n",
        "print(\"acpuate reply\")\n",
        "print(len(data_acup_reply))\n",
        "\n",
        "# concatenate all data\n",
        "data = pd.concat([data_herbal, data_im, data_qg_tweet, data_qg_reply, data_acup_tweet, data_acup_reply], axis=0)"
      ],
      "metadata": {
        "id": "GLCWmlhyoLmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s11JbuTvCFL7"
      },
      "outputs": [],
      "source": [
        "# create label column in numerical form\n",
        "numLabel = []\n",
        "pos_count=0\n",
        "neu_count=0\n",
        "neg_count=0\n",
        "for label in data.label:\n",
        "  if label == \"positive\" or label == \"P\":\n",
        "    numLabel.append(0)\n",
        "    pos_count+=1\n",
        "  elif label == \"neutral\" or label == \"NU\" or label == \"IC\":\n",
        "    numLabel.append(1)\n",
        "    neu_count+=1\n",
        "  elif label == \"negative\" or label == \"NE\" or label == \"N\":\n",
        "    neg_count+=1\n",
        "    numLabel.append(2)\n",
        "  else:\n",
        "    print(\"Unrecognized label {}\".format(label))\n",
        "\n",
        "data[\"sentiment\"] = numLabel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY4pVeOCKv1B"
      },
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**TCM Data Analysis and Cleaning**\n",
        "\n",
        "**-----------------------------------------**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODBZV9c9-BXP"
      },
      "outputs": [],
      "source": [
        "# brief analysis on hashtag\n",
        "def find_hashtags(tweet):\n",
        "    return re.findall('(#[A-Za-z]+[A-Za-z0-9-_]+)', tweet)\n",
        "  \n",
        "data['hashtag'] = data.content.apply(find_hashtags)\n",
        "data.head(10)\n",
        "\n",
        "hashtag_list = data['hashtag'].to_list()\n",
        "flat_hashtags_df = pd.DataFrame([item for sublist in hashtag_list for item in sublist])\n",
        "flat_hashtags_df.shape\n",
        "#change the name of the column to hashtags\n",
        "flat_hashtags_df.columns = ['hashtag']\n",
        "flat_hashtags_df.head()\n",
        "print(\"Total hashtags: \", len(flat_hashtags_df['hashtag']))\n",
        "print(\"Repeated hashtags: \", len(flat_hashtags_df['hashtag'].unique()))\n",
        "flat_hashtags_df['hashtag'].value_counts()[:20].plot(kind='barh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KZdeCm3yVI7"
      },
      "outputs": [],
      "source": [
        "# clean data, remove emmoji, weblink, etc.\n",
        "import emoji \n",
        "\n",
        "def clean(tweet):\n",
        "  txt = re.sub(r\"https?://\\S+\", \"\", tweet) #remove hyperlink\n",
        "  txt = re.sub(\"\\n\", \" \", txt)\n",
        "  txt = re.sub(\":\", \" \", txt)\n",
        "  txt = re.sub(r\"&amp\", \" \", txt)\n",
        "  txt = re.sub(r'@[A-Za-z0-9_]+[A-Za-z0-9-_]+', '', txt) #remove mention\n",
        "  txt = re.sub(r'#[A-Za-z]+[A-Za-z0-9-_]+', '', txt)\n",
        "  txt = re.sub(\"_\", \" \", txt)\n",
        "  txt = emoji.replace_emoji(txt, replace='')\n",
        "  return txt\n",
        "\n",
        "data.content = data.content.apply(clean)\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb0S6Yuz5Gvv"
      },
      "outputs": [],
      "source": [
        "# check label distribution\n",
        "sns.countplot(data.sentiment)\n",
        "plt.xlabel('sentiment');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6fxXdbRs4UZ"
      },
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Prepare fine-tune**\n",
        "\n",
        "**-----------------------------------------**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create model for fine-tune\n",
        "modelTCM = SentimentClassifier(NUM_SENTIMENT)\n",
        "\n",
        "# load pretrained checkpoint (general domain)\n",
        "modelTCM.load_state_dict(torch.load(path + PRE_TRAINED_DICT_NAME))\n",
        "modelTCM = modelTCM.to(device)"
      ],
      "metadata": {
        "id": "_AeesKOFWsC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data to train, eval, test\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKER = 2\n",
        "\n",
        "data_train, data_test = train_test_split(data, test_size=0.3, random_state=RANDOM_SEED)\n",
        "data_val, data_test = train_test_split(data_test, test_size=0.5, random_state=RANDOM_SEED)\n",
        "\n",
        "train_data_loader = generate_dataloader(data_train, tokenizer, MAX_SEQ_LEN, BATCH_SIZE, NUM_WORKER)\n",
        "val_data_loader = generate_dataloader(data_val, tokenizer, MAX_SEQ_LEN, BATCH_SIZE, NUM_WORKER)\n",
        "test_data_loader = generate_dataloader(data_test, tokenizer, MAX_SEQ_LEN, BATCH_SIZE, NUM_WORKER)"
      ],
      "metadata": {
        "id": "Lelt6tfGXAqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for the data distribution\n",
        "sns.countplot(data_train.sentiment)\n",
        "plt.xlabel('sentiment');\n",
        "plt.title('train');\n",
        "\n",
        "sns.countplot(data_val.sentiment)\n",
        "plt.xlabel('sentiment');\n",
        "plt.title('val');\n",
        "\n",
        "sns.countplot(data_test.sentiment)\n",
        "plt.xlabel('sentiment');\n",
        "plt.title('test');"
      ],
      "metadata": {
        "id": "z65_mm0GL6W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the code below if you start fine-tunning directly\n",
        "\n",
        "# hyperparameters\n",
        "EPOCHS = 10\n",
        "\n",
        "# optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# learning rate scheduler # TODO\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# loss function\n",
        "# uncomment code below if you want to use weight cross-entropy function\n",
        "# total_count = pos_count + neu_count + neg_count\n",
        "# class_weight = torch.tensor([total_count/pos_count,total_count/neu_count,total_count/neg_count])\n",
        "# loss_fn = nn.CrossEntropyLoss(class_weight).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "qnhYWu5-X0cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_ft = train(EPOCHS, modelTCM, train_data_loader, val_data_loader, data_train, data_val, loss_fn, optimizer, scheduler, device, 'checkpoints/'+PRE_TRAINED_MODEL_NAME+'/fine_tune_model_dict.bin')"
      ],
      "metadata": {
        "id": "ZwB65d33YWEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Evaluate TCM Fine-tune Result**\n",
        "\n",
        "**-----------------------------------------**"
      ],
      "metadata": {
        "id": "qmYQogQrtKq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this line if you reload this notebook and wish to continue from previous checkpoint\n",
        "# modelTCM.load_state_dict(torch.load(path + 'checkpoints/'+PRE_TRAINED_MODEL_NAME+'/fine_tune_model_dict_shuffle_llr_gen_entire.bin'))\n",
        "# modelTCM = modelTCM.to(device)\n",
        "\n",
        "test_acc, test_loss = eval(\n",
        "  modelTCM,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(data_test)\n",
        ")\n",
        "\n",
        "print(\"Test accuracy {}\".format(test_acc.item()))"
      ],
      "metadata": {
        "id": "VgsACQaezojT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-----------------------------------------**\n",
        "\n",
        "**Further Analysis**\n",
        "\n",
        "**-----------------------------------------**"
      ],
      "metadata": {
        "id": "h8_ODwG6tf16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check training and val accuracy\n",
        "for i in range(len(history_ft['train_acc'])):\n",
        "  history_ft['train_acc'][i] = history_ft['train_acc'][i].cpu()\n",
        "\n",
        "for i in range(len(history_ft['val_acc'])):\n",
        "  history_ft['val_acc'][i] = history_ft['val_acc'][i].cpu()\n",
        "\n",
        "plt.plot(history_ft['train_acc'], label='train')\n",
        "plt.plot(history_ft['val_acc'], label='validation')\n",
        "plt.title('TCM: Fine Tune')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "metadata": {
        "id": "esWlWiJX-6h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision, recall, F-1**"
      ],
      "metadata": {
        "id": "5SqK9VorilSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function for getting predictions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_predictions(model, data_loader):\n",
        "  # freeze backprop gradient compute\n",
        "  model = model.eval()\n",
        "  \n",
        "  predictions = []\n",
        "  labels = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for input_ids, attention_mask, label in data_loader:\n",
        "      # convert to acceleration unit\n",
        "      input_ids = text_input.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # forward\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      # get prediction\n",
        "      _, prediction = torch.max(outputs, dim=1)\n",
        "\n",
        "      predictions.extend(prediction)\n",
        "      labels.extend(label)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  labels = torch.stack(labels).cpu()\n",
        "\n",
        "  return predictions, labels"
      ],
      "metadata": {
        "id": "XgRCIeZ-ZiVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check precision, recall, and F-1\n",
        "y_pred, y_test = get_predictions(modelTCM, test_data_loader)\n",
        "target_names = ['positive', 'neutral', 'negative']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "sJs-NH03eKz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion matrix**"
      ],
      "metadata": {
        "id": "PM5Ue2tBipop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function for visualizing confusion matrix\n",
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.title('Confusion Matrix - w pretrain, w/o fine-tune')\n",
        "  plt.xlabel('Prediction');\n",
        "  plt.ylabel('Ground Truth')"
      ],
      "metadata": {
        "id": "41MrHV6yZkI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "confusion_mat = pd.DataFrame(confusion_mat, index=target_names, columns=target_names)\n",
        "show_confusion_matrix(confusion_mat)"
      ],
      "metadata": {
        "id": "SBcufIA1ifGg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}